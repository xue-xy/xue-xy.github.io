{"posts":[{"title":"NuXmv学习笔记","content":"NuXmv学习笔记 Tip: Fram condition. Variables that are not constrained in the transition will change their value non-deterministically. 安装 去官网上选择适合自己系统的版本下载即可，这里使用的是mac版本。在文件夹下的/bin/文件夹中的nuXmv便是执行文件。 想要进行交互式操作可以在终端定位到该文件夹后执行./nuXmv -int即可。也可以吧nuxmv变成全局的命令，可在zshrc文件中添加 alias nuxmv=$FilePath/bin/nuXmv 其中FilePath是下载的文件夹的路径。 使用Apple Silicon的注意事项 NuXmv需要x86版本的gmp，这个可以使用x86版本的homebrew进行安装。x86版本的homebrew配置方法可以见这篇文章。 有限状态系统 网上的几篇教程. 这个教程中主要讨论了在有限状态情况下的系统建模与验证，与NuSmv的情况有些相似。 read_model -i filename读取模型文件。 show_property展示模型文件中的性质。 show_traces查看某个迹。 无限状态系统 有些命令在无限状态的模型中无法使用，这里记录一些在无限状态情况下使用的命令。 go_mast 初始化模型，和原来的go有些相似。 msat_pick_state从初始状态中挑选一个作为当前的状态，并可以以此展开一条新的路径。 msat_simulate 进行模拟执行。-k length表示模拟的步数。 msat_check_invar_bmc使用BMC进行不变式检查，直接用有些问题。 check_invar_ic3使用msatic3进行不变式检验，感觉很好用。-n指定要检查的性质，-k指定步数。 msat_check_ltlspec_bmc使用BMC进行LTL性质检查。 check_ltlspec_ic3使用ic3进行LTL性质检查。和上面的的都可用，但是在无限状态下LTL性质难以被检查出来。 注意事项 TRANS中的条件最好是互相不重复，否则可能会出现混淆导致无法执行。 ","link":"https://xue-xy.github.io/post/Nuxmv学习笔记/"},{"title":"Paper Reading - April, 2021","content":"Token-Modification Adversarial Attacks for Natural Language Processing: A Survey A Survey about adversarial attack using token modification on NLP tasks. Token modification methods replace one wiht another insert a token delete a toekn change token ordering Token replacement ideas. Replace a word with any word. Often used in character level. Attack in embedding space attacks for images. Replace some character with similar-looking characters. Character levle. The mapping is constructed by human or by treating characters as images. Replace tokens with hunman errors like misspelling on Wiki or adjacent characters on keyboard. Close point in embedding space are similar words. Use counter-fitted embeddings to select synonyms. Replace target token with a mask and use a language model to predict it. Loss guided $ \\partial{l} / \\partial{x} $ or $\\partial{f(x)} / \\partial{x} $. The latter is for specific class attack. Repairing Deep Neural Networks: Fix Patterns and Challenges An empirical study about bug fix patterns in neural network developing. Bug fix pattern includes loss function, add layer, connection, activation, iterations, optimizer, accuracy metric, etc. The bugs can be roughly classified as network-related and non-network-related. Non-network-related bugs include version bugs and data dimension bugs and so on. They casue code crash. Network-related bugs are about network structue or loss function. They usually don't make code break down, but they lead to bad performance. Changing these parts of the network may increse prediction accuracy. Adversarial Sample Detection for Deep Neural Network through Model Mutation Testing Their observation is adversarial samples are much more sensitive than normal samples if we impose random mutations on the DNN. Reading. NeuroDiff: scalable differential verification of neural networks using fine-grained approximation Reading. Multiple-boundary clustering and prioritization to promote neural network retraining Reading. ","link":"https://xue-xy.github.io/post/paper-reading/"},{"title":"Mediator源码结构","content":"最新的代码发布在https://github.com/xue-xy/Mediator_origin。 语法文件 src-antlr是mediator的语法文件，语法使用ANTLR进行处理，由其生成的文件在org.fmgroup.mediator.languange.generated中。 src中的文件 common core. 命令行启动入口。 environment plugin plugins. 一些附加的插件，比如向其它语言的转换器，scheduler等。 language 这一部分内容较多，所以要单独进行记录。 entity. 自动机和系统的实现。在转移的部分，Transition是接口，TransitionSingle和TransitionGroup是它的两个实现。自动机中的Transition是一个Transition的ArrayList。 function generated. 存放由语法文件经由ANTLR自动生成的文件。Mediator中只用了Listener模式进行生成。但在实际分析中并没有使用。 property scope. 其中的VariableDeclarationCollection是变量声明的集合。VaribleDeclaration是单个的变量声明。 statement. 保存了各种类型的Statement。接口Statement是parser的入口。接口Statements没有进行实现，一条转移中有多个命令的处理是通过分别处理每条语句的方式进行的。 term. 各种类型项的具体实现。 type. 保存了各个类型的实现及处理。接口Type中的静态方法parse将type进行分类。 Program. 程序的入口，其中的parseFile方法是parse的入口，它读取文件然后进行parse，最后得到prog的context。 其它文件 resource中放置的是一些测试例子的文件。 scripts是启动时的一些脚本文件。 额外注释 各个内容类中的fromContext方法是从context构建成自己的数据结构。antlr的contex是一个序列，记录着从当前节点到根节点的路径。 meta是记录一系列的term，用法尚待考察。 parse得到的结构是一个树状的结构。parse的过程是从根到叶这个方向进行的，每个结构都记录自己的父结构。 待解决的问题 Double类型的值不能使用。原来实现了DoubleValue，但是没有在Term中引过去（已经解决）。 refactor方法还没有处理类型之间的映射，有些类别的refactor方法也没有实现。在schedule和复制的时候会用到refactor方法（部分类型的已经解决）。 类型检查没有做。变量和其值的类型可能不对应。作条件的有可能不是bool类型的项。 schedule得到的自动机可读性差，其中转移的条件过长，没有进行处理。 端口只有一个字母A的时候语法错误，目前原因未知。可能是由于ANTLR语法定义优先级的问题。 ","link":"https://xue-xy.github.io/post/mediator源码结构/"},{"title":"ANTLR学习记录","content":"看到知乎用户陈乐群的两篇ANTLR笔记（一）（二） 在CSDN上看到关于ANTLR在Intellij IDEA上的使用的文章（一）（二）（三）（四）。对进行了标注的语法规则使用visitor进行访问和用递归的方式进行处理的思路是一样的。 ANTLR进行将文件转为语法树的流程 过程为：文件流 -&gt; 字符流 -&gt; 词法解析器 -&gt; token流 -&gt; 语法解析器 -&gt; 从语法入口进入得到语法树。 import java.io.*; import org.antlr.v4.runtime.*; import org.antlr.v4.runtime.tree.*; InputStream is = new FileInputStream(file); \\\\将输入文件转为输入数据流 DSLLexer lexer = new DSLLexer(CharStreams.fromStream(is)); \\\\括号里为将输入流转化为字符流，然后送入词法分析器 CommonTokenStream ts = new CommonTokenStream(lexer); \\\\词法分析后得到token流 DSLParser parser = new DSLParser(ts); \\\\生成语法分析器 ParseTree tree = parser.prog(); \\\\从入口开始进行语法分析 也可以通过下面方法从某个规则进入 DSLParser.MainContext prog = parser.prog(); 每条语法规则都有对应的context，可以根据context的不同去对具体的单元进行不同的处理。Mediator中是这样做的。 ","link":"https://xue-xy.github.io/post/antlr学习笔记/"},{"title":"使用github+Gridea建立个人博客","content":"待续。 ","link":"https://xue-xy.github.io/post/使用github+gridea搭建博客/"}]}